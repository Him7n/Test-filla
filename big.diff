diff --git a/src/docFillerCore/engines/consensusEngine.ts b/src/docFillerCore/engines/consensusEngine.ts
index 18fd0a3..1117c30 100644
--- a/src/docFillerCore/engines/consensusEngine.ts
+++ b/src/docFillerCore/engines/consensusEngine.ts
@@ -50,7 +50,9 @@ class ConsensusEngine {
     fieldType: QType,
   ): Promise<LLMResponse | null> {
     const responses = [];
-    for (const [llmType, weight] of ConsensusEngine.llmWeights.entries()) {
+    const entries = Array.from(ConsensusEngine.llmWeights.entries());
+    for (let i = 0; i < entries.length; i++) {
+      const [llmType, weight] = entries[i] as [LLMEngineType, number];
       try {
         const llm = LLMEngine.getInstance(llmType);
         const response = await llm.getResponse(promptString, fieldType);
@@ -67,9 +69,10 @@ class ConsensusEngine {
               value: response ?? {},
             });
           }
+        } else {
+          console.log(response);
         }
       } catch (error) {
-        // Handle the error here
         console.error(error);
         continue;
       }
diff --git a/src/docFillerCore/engines/gptEngine.ts b/src/docFillerCore/engines/gptEngine.ts
index 0c6db9f..f6d1e8b 100644
--- a/src/docFillerCore/engines/gptEngine.ts
+++ b/src/docFillerCore/engines/gptEngine.ts
@@ -1,3 +1,8 @@
+/* eslint-disable @typescript-eslint/no-unsafe-member-access */
+/* eslint-disable @typescript-eslint/no-unsafe-return */
+/* eslint-disable @typescript-eslint/no-unsafe-assignment */
+/* eslint-disable no-console */
+/* eslint-disable @typescript-eslint/no-explicit-any */
 import process from 'process';
 
 import { Ollama } from '@langchain/ollama';
@@ -22,137 +27,110 @@ import {
   getAnthropicApiKey,
 } from '@utils/getProperties';
 
+type LLMInstance =
+  | ChatOpenAI
+  | Ollama
+  | ChatGoogleGenerativeAI
+  | ChatAnthropic
+  | ChatMistralAI;
+
 export class LLMEngine {
   private static instance: LLMEngine;
   private static engine: LLMEngineType;
-  private static openai: ChatOpenAI;
-  private static ollama: Ollama;
-  private static gemini: ChatGoogleGenerativeAI;
-  private static antropic: ChatAnthropic;
-  private static mistral: ChatMistralAI;
-
-  private chatGptApiKey: string | undefined;
-  private geminiApiKey: string | undefined;
-  private mistralApiKey: string | undefined;
-  private anthropicApiKey: string | undefined;
+  private static instances: Record<LLMEngineType, LLMInstance | undefined> = {
+    [LLMEngineType.ChatGPT]: undefined,
+    [LLMEngineType.Gemini]: undefined,
+    [LLMEngineType.Ollama]: undefined,
+    [LLMEngineType.Mistral]: undefined,
+    [LLMEngineType.Anthropic]: undefined,
+  };
+
+  private static apiKeys: Record<string, string | undefined> = {
+    chatGptApiKey: undefined,
+    geminiApiKey: undefined,
+    mistralApiKey: undefined,
+    anthropicApiKey: undefined,
+  };
 
   private constructor(engine: LLMEngineType) {
     LLMEngine.engine = engine;
 
-    this.fetchApiKeys()
+    LLMEngine.fetchApiKeys()
       .then(() => {
-        console.log('API keys fetched:', {
-          chatGptApiKey: this.chatGptApiKey,
-          geminiApiKey: this.geminiApiKey,
-          mistralApiKey: this.mistralApiKey,
-          anthropicApiKey: this.anthropicApiKey,
-        });
+        console.log('API keys fetched:', LLMEngine.apiKeys);
 
-        LLMEngine.instantiateEngine(LLMEngine.engine);
+        try {
+          LLMEngine.instantiateEngine(LLMEngine.engine);
+        } catch (error) {
+          console.error('Error instantiating engine:', error);
+        }
       })
       .catch((error) => {
         console.error('Error fetching API keys:', error);
       });
   }
 
-  private async fetchApiKeys(): Promise<void> {
-    this.chatGptApiKey = await getChatGptApiKey();
-    this.geminiApiKey = await getGeminiApiKey();
-    this.mistralApiKey = await getMistralApiKey();
-    this.anthropicApiKey = await getAnthropicApiKey();
+  private static async fetchApiKeys(): Promise<void> {
+    LLMEngine.apiKeys.chatGptApiKey = await getChatGptApiKey();
+    LLMEngine.apiKeys.geminiApiKey = await getGeminiApiKey();
+    LLMEngine.apiKeys.mistralApiKey = await getMistralApiKey();
+    LLMEngine.apiKeys.anthropicApiKey = await getAnthropicApiKey();
   }
 
-  public static instantiateEngine(
-    engine: LLMEngineType,
-  ):
-    | ChatOpenAI
-    | Ollama
-    | ChatGoogleGenerativeAI
-    | ChatAnthropic
-    | ChatMistralAI {
+  public static instantiateEngine(engine: LLMEngineType): LLMInstance {
+    if (LLMEngine.instances[engine]) {
+      return LLMEngine.instances[engine];
+    }
+
     switch (engine) {
-      case LLMEngineType.ChatGPT: {
-        if (LLMEngine.openai) {
-          return LLMEngine.openai;
-        }
-        if (!LLMEngine.instance.chatGptApiKey) {
-          throw new Error('ChatGPT API key is not defined');
-        }
-        LLMEngine.openai = new ChatOpenAI({
+      case LLMEngineType.ChatGPT:
+        LLMEngine.instances[engine] = new ChatOpenAI({
           model: 'gpt-4',
-          apiKey: LLMEngine.instance.chatGptApiKey,
+          apiKey: LLMEngine.apiKeys.chatGptApiKey as string,
         });
-        return LLMEngine.openai;
-      }
-
-      case LLMEngineType.Gemini: {
-        if (LLMEngine.gemini) {
-          return LLMEngine.gemini;
-        }
-        if (!LLMEngine.instance.geminiApiKey) {
-          throw new Error('Gemini API key is not defined');
-        }
-        LLMEngine.gemini = new ChatGoogleGenerativeAI({
+        break;
+      case LLMEngineType.Gemini:
+        LLMEngine.instances[engine] = new ChatGoogleGenerativeAI({
           model: 'gemini-pro',
           temperature: 0,
           maxRetries: 2,
-          apiKey: LLMEngine.instance.geminiApiKey,
+          apiKey: LLMEngine.apiKeys.geminiApiKey as string,
         });
-        return LLMEngine.gemini;
-      }
-
-      case LLMEngineType.Ollama: {
-        if (LLMEngine.ollama) {
-          return LLMEngine.ollama;
-        }
-        LLMEngine.ollama = new Ollama({
+        break;
+      case LLMEngineType.Ollama:
+        LLMEngine.instances[engine] = new Ollama({
           model: 'gemma2:2b',
           temperature: 0,
           maxRetries: 2,
         });
-        return LLMEngine.ollama;
-      }
-
-      case LLMEngineType.Mistral: {
-        if (LLMEngine.mistral) {
-          return LLMEngine.mistral;
-        }
-        if (!LLMEngine.instance.mistralApiKey) {
-          throw new Error('Mistral API key is not defined');
-        }
-        LLMEngine.mistral = new ChatMistralAI({
+        break;
+      case LLMEngineType.Mistral:
+        LLMEngine.instances[engine] = new ChatMistralAI({
           model: 'mistral-large-latest',
           temperature: 0,
           maxRetries: 2,
-          apiKey: LLMEngine.instance.mistralApiKey,
+          apiKey: LLMEngine.apiKeys.mistralApiKey as string,
         });
-        return LLMEngine.mistral;
-      }
-
-      case LLMEngineType.Anthropic: {
-        if (LLMEngine.antropic) {
-          return LLMEngine.antropic;
-        }
-        if (!LLMEngine.instance.anthropicApiKey) {
-          throw new Error('Anthropic API key is not defined');
-        }
-        LLMEngine.antropic = new ChatAnthropic({
+        break;
+      case LLMEngineType.Anthropic:
+        LLMEngine.instances[engine] = new ChatAnthropic({
           model: 'claude-3-haiku-20240307',
           temperature: 0,
           maxRetries: 2,
-          apiKey: LLMEngine.instance.anthropicApiKey,
+          apiKey: LLMEngine.apiKeys.anthropicApiKey as string,
         });
-        return LLMEngine.antropic;
-      }
+        break;
     }
+
+    return LLMEngine.instances[engine];
   }
 
   public static getInstance(engine: LLMEngineType): LLMEngine {
-    if (LLMEngine.instance && LLMEngine.engine === engine) {
-      return LLMEngine.instance;
+    if (!LLMEngine.instance) {
+      LLMEngine.instance = new LLMEngine(engine);
+    } else {
+      LLMEngine.instantiateEngine(engine);
     }
-
-    LLMEngine.instance = new LLMEngine(engine);
     return LLMEngine.instance;
   }
 
@@ -180,45 +158,15 @@ export class LLMEngine {
     promptText: string,
     questionType: QType,
   ): Promise<LLMResponse | null> {
+    console.log(promptText);
+    console.log(questionType);
     if (!promptText) {
       return null;
     }
     try {
-      let response = null;
       const parser = LLMEngine.getParser(questionType);
-      let modelInstance;
-      switch (LLMEngine.engine) {
-        case LLMEngineType.ChatGPT: {
-          if (LLMEngine.openai) {
-            modelInstance = LLMEngine.openai;
-          }
-          break;
-        }
-        case LLMEngineType.Gemini: {
-          if (LLMEngine.gemini) {
-            modelInstance = LLMEngine.gemini;
-          }
-          break;
-        }
-        case LLMEngineType.Ollama: {
-          if (LLMEngine.ollama) {
-            modelInstance = LLMEngine.ollama;
-          }
-          break;
-        }
-        case LLMEngineType.Mistral: {
-          if (LLMEngine.mistral) {
-            modelInstance = LLMEngine.mistral;
-          }
-          break;
-        }
-        case LLMEngineType.Anthropic: {
-          if (LLMEngine.antropic) {
-            modelInstance = LLMEngine.antropic;
-          }
-          break;
-        }
-      }
+      const modelInstance = LLMEngine.instances[LLMEngine.engine];
+
       if (modelInstance) {
         const chain = RunnableSequence.from([
           PromptTemplate.fromTemplate(
@@ -228,7 +176,7 @@ export class LLMEngine {
           parser,
         ]);
 
-        response = await chain.invoke({
+        const response = await chain.invoke({
           question: promptText,
           format_instructions: parser.getFormatInstructions(),
         });
@@ -237,8 +185,8 @@ export class LLMEngine {
       return null;
     } catch (error) {
       console.error('Error getting response:', error);
+      return null;
     }
-    return null;
   }
 
   private patchResponse(response: any, questionType: QType): LLMResponse {
@@ -280,6 +228,7 @@ export class LLMEngine {
   ): StructuredOutputParser<any> | DatetimeOutputParser | StringOutputParser {
     switch (questionType) {
       case QType.TEXT:
+      case QType.PARAGRAPH:
         return new StringOutputParser();
       case QType.TEXT_EMAIL:
         return StructuredOutputParser.fromNamesAndDescriptions({
@@ -290,7 +239,6 @@ export class LLMEngine {
         return StructuredOutputParser.fromNamesAndDescriptions({
           answer: 'Give Correct Url corresponding to given question',
         });
-
       case QType.DATE:
       case QType.TIME:
       case QType.DATE_AND_TIME:
@@ -301,7 +249,6 @@ export class LLMEngine {
       case QType.TIME_WITH_MERIDIEM:
       case QType.DURATION:
         return new DatetimeOutputParser();
-
       case QType.LINEAR_SCALE:
         return StructuredOutputParser.fromZodSchema(
           z.object({
@@ -312,14 +259,10 @@ export class LLMEngine {
               ),
           }),
         );
-
       case QType.DROPDOWN:
         return StructuredOutputParser.fromNamesAndDescriptions({
           answer: "answer to the user's question",
         });
-      case QType.PARAGRAPH:
-        return new StringOutputParser();
-
       case QType.CHECKBOX_GRID: {
         const checkboxGridColSchema = z.object({
           data: z
@@ -348,7 +291,6 @@ export class LLMEngine {
 
         return StructuredOutputParser.fromZodSchema(checkboxGridArraySchema);
       }
-
       case QType.MULTIPLE_CHOICE_GRID: {
         const multipleChoiceGridRowSchema = z.object({
           row: z
@@ -373,7 +315,6 @@ export class LLMEngine {
           multipleChoiceGridArraySchema,
         );
       }
-
       case QType.MULTIPLE_CHOICE:
       case QType.MULTIPLE_CHOICE_WITH_OTHER:
       case QType.MULTI_CORRECT:
diff --git a/src/utils/settings.ts b/src/utils/settings.ts
index 12dc087..09aaebc 100644
--- a/src/utils/settings.ts
+++ b/src/utils/settings.ts
@@ -50,7 +50,7 @@ class Settings {
 
   public async getEnableConsensus(): Promise<boolean> {
     if (!this.enableConsensus) {
-      this.enableConsensus = (await getEnableConsensus()) || true;
+      this.enableConsensus = (await getEnableConsensus()) || false;
     }
     return this.enableConsensus;
   }
